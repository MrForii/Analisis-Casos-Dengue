{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - 2018.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - 2019.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - 2020.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - Julio 2021.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - Diciembre 2021.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - 2022.csv\n",
      "\n",
      "âœ… Archivo Procesado: archivos_csv/Analisis de Datos Dengue y Zika - 2023.csv\n",
      "\n",
      "ðŸš¨ Los archivos han sido procesados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Vamos a crear un diccionario con los diferentes nombres de los archivos a procesar\n",
    "\n",
    "# Definimos los nombres\n",
    "nombres = [\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - 2018.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - 2019.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - 2020.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - Julio 2021.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - Diciembre 2021.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - 2022.csv\",\n",
    "    \"archivos_csv/Analisis de Datos Dengue y Zika - 2023.csv\",\n",
    "]\n",
    "\n",
    "# Ahora las columnas que usaremos de cada archivo\n",
    "columnas = [\n",
    "    [\"provincia_id\", \"provincia_nombre\", \"anio\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"provincia_id\", \"provincia_nombre\", \"aÃ±o\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"provincia_id\", \"provincia_nombre\", \"aÃ±o\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"provincia_id\", \"provincia_nombre\", \"aÃ±o\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"provincia_nombre\", \"provincia_id\", \"aÃ±o\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"provincia_id\", \"provincia_nombre\", \"aÃ±o\", \"semanas_epidemiologicas\", \"evento_nombre\", \"cantidad_casos\"],\n",
    "    [\"ID_PROV_INDEC_RESIDENCIA\", \"PROVINCIA_RESIDENCIA\", \"ANIO_MIN\", \"SEPI_MIN\", \"EVENTO\", \"Total\"],\n",
    "            ]\n",
    "\n",
    "# Conformamos el diccionario\n",
    "diccionario_archivos = {}\n",
    "\n",
    "for nombre, columnas in zip(nombres, columnas):\n",
    "    diccionario_archivos[nombre] = {\"nombre\": nombre, \"columnas\": columnas}\n",
    "\n",
    "\n",
    "def procesar_csv(archivo_csv, columnas):\n",
    "    # Cargamos el dataset\n",
    "    df = pd.read_csv(archivo_csv, usecols=columnas)\n",
    "\n",
    "    # Renombramos las columnas\n",
    "    columnas_renombradas = {\n",
    "        columnas[0]: \"id_provincia\",\n",
    "        columnas[1]: \"nombre_provincia\",\n",
    "        columnas[2]: \"anio\",\n",
    "        columnas[3]: \"semana_epidemiologica\",\n",
    "        columnas[4]: \"nombre_evento\",\n",
    "        columnas[5]: \"total_casos\"\n",
    "        }\n",
    "    \n",
    "    df.rename(columns=columnas_renombradas, inplace=True)\n",
    "\n",
    "    # Completamos aquellos registros que no tengan cargados datos en el \"nombre_provincia\" con \"Sin Especificar\"\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].fillna(\"Sin Especificar\")\n",
    "\n",
    "    # Lo mismo para los que tienen *sin dato*\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].str.replace(\"*sin dato*\", \"Sin Especificar\")\n",
    "\n",
    "    # Tambien para los que tienen (en blanco)\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].str.replace(\"(en blanco)\", \"Sin Especificar\")\n",
    "\n",
    "    # Corregimos errores de escritura en los datos\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].str.replace(\"SAnta Cruz\", \"Santa Cruz\")\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].str.replace(\"SAnta Fe\", \"Santa Fe\")\n",
    "\n",
    "\n",
    "    # Reemplazamos las tildes para que el resultado sea optimo\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].map(lambda x: x.replace(\"Ã¡\", \"a\"))\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].map(lambda x: x.replace(\"Ã©\", \"e\"))\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].map(lambda x: x.replace(\"Ã­\", \"i\"))\n",
    "    df[\"nombre_provincia\"] = df[\"nombre_provincia\"].map(lambda x: x.replace(\"Ã³\", \"o\"))\n",
    "\n",
    "    # Filtrar por \"nombre_evento\" == \"Dengue\"\n",
    "    df = df.loc[df[\"nombre_evento\"] == \"Dengue\"]\n",
    "\n",
    "    # Agrupar por \"id_provincia\", \"provincia_nombre\", \"anio\", \"evento_nombre\", \"semanas_epidemiologicas\"\n",
    "    df_agrupado = df.groupby([\"id_provincia\", \"nombre_provincia\", \"anio\", \"semana_epidemiologica\"])\n",
    "\n",
    "    # Calcular el total de casos por semana\n",
    "    df = df_agrupado[\"total_casos\"].agg(\"sum\")\n",
    "\n",
    "    # Convertir el Series a un DataFrame\n",
    "    df_procesado = df.to_frame()\n",
    "\n",
    "    print(\"âœ… Archivo Procesado:\", archivo_csv)\n",
    "    print()\n",
    "\n",
    "    return df_procesado\n",
    "\n",
    "# Vamos a analizar todos los datasets secuencialmente, e iremos guardando los archivos parciales en una lista\n",
    "df_temporal = []\n",
    "\n",
    "for nombre_archivo in diccionario_archivos:\n",
    "    columnas = diccionario_archivos[nombre_archivo][\"columnas\"]\n",
    "    nombre = diccionario_archivos[nombre_archivo][\"nombre\"]\n",
    "    df = procesar_csv(nombre, columnas)\n",
    "    df_temporal.append(df)\n",
    "\n",
    "df = pd.concat(df_temporal)\n",
    "\n",
    "df[\"total_casos\"].astype(\"int\")\n",
    "\n",
    "df.to_csv(\"archivos_csv/casos_dengue_2018_2023.csv\")\n",
    "\n",
    "print(\"ðŸš¨ Los archivos han sido procesados exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
